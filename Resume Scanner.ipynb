{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17344f6-793f-44cd-b3f9-2fc0610bbf01",
   "metadata": {},
   "source": [
    "<h1 style= 'background:yellow; color:orange;alignment:center'>Resume Scanner</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c19726-571e-4a7e-b34d-c335444a5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b44668a-f901-4702-90f6-e9208d005811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "359c48b4-e615-4765-9b21-a68be3ba1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"resumes/\" #C:/Users/admin/Downloads/\n",
    "resumes = {}\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        resumes[file] = extract_text_from_pdf(os.path.join(folder, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "243b7da4-5b02-46a0-a6ca-84c5ba14ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc5f1398-b6f1-4f60-a123-f080989f3e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0716a0f-36d0-4ab0-b751-3c7f31efbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75d4165b-74f4-414b-887e-e34b4ee3df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dbfd4e6-e116-4b2c-904e-fb08b53e10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter JD: Data Analyst || Virtual Opportunity  About the Role  We are looking for a detail-oriented and analytical Data Analyst who can turn raw data into meaningful insights. This role requires strong technical skills, problem-solving ability, and a proactive mindset to support decision-making across teams. Responsibilities  Collect, clean, and analyze data from various sources to identify trends, insights, and opportunities. Build automated dashboards and reports using Google Sheets / Advanced Excel. Develop data scripts and automation workflows using Python. Collaborate with cross-functional teams to understand business needs and provide data-driven recommendations. Work with large datasets to create visualizations, models, and performance tracking tools. Optimize and automate repetitive tasks; App Script knowledge will be a plus. Utilize ChatGPT or AI tools to enhance workflows, generate insights, and support data processes. Maintain data accuracy, quality, and integrity across all analytics outputs. Communicate findings clearly through summaries, presentations, and visual reports. Required Skills & Qualifications  Minimum 2.5 years of experience as a Data Analyst or similar role. Strong proficiency in Python for data analysis, automation, and scripting. Advanced skills in Google Sheets / Excel, including formulas, dashboards, pivot tables, and automation. Strong logical reasoning and problem-solving skills- ability to understand patterns, create structured solutions, and think analytically. ChatGPT /AI Tools ability to use AI to assist in analysis, automation, and insight generation. Strong analytical mindset with attention to detail and problem-solving skills. Excellent communication and documentation abilities. Intent to work, take ownership, and deliver consistent, high-quality outputs. Knowledge of App Script is a strong advantage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apeksha_Muluk_Resume.pdf: 0.14\n",
      "Rohan_Gaikwad.pdf: 0.00\n",
      "Roshan Ahiwale A (3).pdf: 0.18\n",
      "RutujaMunde_resume.pdf: 0.10\n",
      "SaKet Shinde data analyst resume (1).pdf: 0.14\n",
      "Suraj_Jawale_data_analyst.pdf: 0.18\n",
      "Sushil Ambekar resume.pdf: 0.23\n",
      "VAISHNAVI DUMBRE_RESUME.pdf: 0.15\n",
      "_Suraj_resume (1).pdf: 0.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "jd = str(input(\"Enter JD:\"))\n",
    "documents = [preprocess_text(jd)]+ [preprocess_text(text) for text in resumes.values()]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(documents)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_scores = cosine_similarity(vectors[0:1], vectors[1:]).flatten()\n",
    "\n",
    "for i, (filename, score) in enumerate(zip(resumes.keys(), similarity_scores)):\n",
    "    print(f\"{filename}: {score:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2807bb78-de9a-4ae7-aac5-90bb53d0badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate_name</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sushil Ambekar resume.pdf</td>\n",
       "      <td>23.406112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Suraj_Jawale_data_analyst.pdf</td>\n",
       "      <td>18.156159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roshan Ahiwale A (3).pdf</td>\n",
       "      <td>17.693851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAISHNAVI DUMBRE_RESUME.pdf</td>\n",
       "      <td>15.013406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apeksha_Muluk_Resume.pdf</td>\n",
       "      <td>14.348504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SaKet Shinde data analyst resume (1).pdf</td>\n",
       "      <td>14.035907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_Suraj_resume (1).pdf</td>\n",
       "      <td>13.307027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RutujaMunde_resume.pdf</td>\n",
       "      <td>9.518871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohan_Gaikwad.pdf</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Candidate_name     Scores\n",
       "6                 Sushil Ambekar resume.pdf  23.406112\n",
       "5             Suraj_Jawale_data_analyst.pdf  18.156159\n",
       "2                  Roshan Ahiwale A (3).pdf  17.693851\n",
       "7               VAISHNAVI DUMBRE_RESUME.pdf  15.013406\n",
       "0                  Apeksha_Muluk_Resume.pdf  14.348504\n",
       "4  SaKet Shinde data analyst resume (1).pdf  14.035907\n",
       "8                     _Suraj_resume (1).pdf  13.307027\n",
       "3                    RutujaMunde_resume.pdf   9.518871\n",
       "1                         Rohan_Gaikwad.pdf   0.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Candidate_name\":resumes.keys(), \n",
    "                  'Scores': similarity_scores*100}).sort_values(by= 'Scores', ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63194e-0838-465a-89be-b5f6b040ba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
